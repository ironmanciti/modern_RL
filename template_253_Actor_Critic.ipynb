{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "SXe72SuamiHi",
   "metadata": {
    "id": "SXe72SuamiHi"
   },
   "source": [
    "# 253. One-step Actor-Critic(episodic)\n",
    "\n",
    "- 두개의 parameter set 을 학습 \n",
    "\n",
    "$$\\theta_{t+1}=\\theta_t + \\alpha\\nabla\\log{\\pi_\\theta}(A_t|S_t)[R_{t+1}+\\gamma\\hat{v}(S_{t+1},w) - \\hat{v}(S_t, w)]$$\n",
    "\n",
    "- TD error (delta) \n",
    "$$R_{t+1}+\\gamma\\hat{v}(S_{t+1},w) - \\hat{v}(S_t, w)$$\n",
    "\n",
    "- Value network parameter update\n",
    "$$w \\leftarrow w + \\alpha^w\\delta\\nabla\\hat{v}(S, w)$$\n",
    "\n",
    "- Policy network parameter update\n",
    "$$\\theta \\leftarrow \\theta + \\alpha^\\theta \\delta\\nabla\\log{\\pi}(A|S, \\theta)$$\n",
    "\n",
    "- python 구현 :\n",
    "\n",
    "```python\n",
    "            td_target = r_batch + gamma * model.v(s_next_batch) * (1-done_batch)\n",
    "            delta = td_target - model.v(s_batch)\n",
    "        \n",
    "            pi = model.pi(s_batch)\n",
    "            pi_a = pi.gather(1, a_batch)\n",
    "            \n",
    "            loss = -1 * torch.log(pi_a) * delta + F.smooth_l1_loss(model.v(s_batch), td_target)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb597fe9",
   "metadata": {
    "id": "eb597fe9"
   },
   "source": [
    "### 환경 초기화\n",
    "\n",
    "[LunarLander-v2](https://www.gymlibrary.ml/environments/box2d/lunar_lander/)  \n",
    "[CartPole-v0'](https://www.gymlibrary.ml/environments/classic_control/cart_pole/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdee477",
   "metadata": {
    "id": "6fdee477"
   },
   "source": [
    "### Actor Critic Network 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280b9a5",
   "metadata": {
    "id": "0280b9a5"
   },
   "source": [
    "### main algorithm  작성\n",
    "\n",
    "- LunarLander 약 20 분 소요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dca2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards = []\n",
    " \n",
    "# loop forever(for each episode):\n",
    "for episode in range(N):\n",
    "    # Initialize S (first state of episode)\n",
    "    \n",
    "    \n",
    "    # Loop while S is not terminal(for each time step):\n",
    "    while not done:\n",
    "        # A ~ pi(.|S,theta) - policy network에서 action 하나를 sampling\n",
    "        \n",
    "        # Take action A, observe S', R\n",
    "        \n",
    "        \n",
    "        # S <- S'\n",
    "        \n",
    "            \n",
    "        if done:\n",
    "            \n",
    "            \n",
    "            # delta <- R + gamma * v(S',w) - v(S,w) (if S' is terminal, then v(S',w) = 0)\n",
    "            \n",
    "            # advantage = reward + gamma * v(S',w) - v(S,w) --> advantage = delta\n",
    "            \n",
    "            \n",
    "            # value network parameter update :\n",
    "            # w <- w + alpha * delta * gradient(v(S,w)) \n",
    "            # policy network parameter update :\n",
    "            # theta <- theta + alpha * I * delta * gradient(pi(A|S,theta)) \n",
    "            \n",
    "            \n",
    "            # loss = -1 * policy.logprob(action) * advantage + critic loss\n",
    "            \n",
    "            \n",
    "    if episode % 100 == 0:\n",
    "        avg_score = np.mean(total_rewards[-100:])\n",
    "        print(f'episode {episode},  최근 100 episode 평균 reward {avg_score: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b1641",
   "metadata": {
    "id": "498b1641"
   },
   "source": [
    "### Animate it with Video"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "253_Actor_Critic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
