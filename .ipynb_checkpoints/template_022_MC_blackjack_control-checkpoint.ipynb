{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c46d28cd",
   "metadata": {
    "id": "c46d28cd"
   },
   "source": [
    "# 022_MC_blackjack_control\n",
    "## Suntton p.101 \n",
    "### On-Policy First-Visit MC control(for e-soft policies) for optimum policy pi*\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/9985DE425C7C66AD28\" width=600 />\n",
    "\n",
    "## policy 를 개선하여 optimal policy를 찾기 위한 알고리즘 \n",
    "\n",
    "- e-soft policy $\\pi$, state-action value Q(s, a) 를 random 하게 초기화   \n",
    "\n",
    "- 각 state-action pair  로 부터의 return 을 저장할 Returns(s, a) empty list 생성  \n",
    "\n",
    "- Policy $\\pi$ 를 이용하여 episode 생성\n",
    "- 각 state-action pair 에 대해, first occurrence 이후의 return 들을 더함. Q(s, a) = first occurrence 이후의 모든 return 의 평균.\n",
    "- 각 state 에 대하여 Policy 가 해당 state 의 가장 valuable 한 action을 선택할 확률 증가시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64908b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize\n",
    "#pi <- an arbitrary e-soft policy (초기 policy)\n",
    "#Q(s,a) 초기화 for all s, a\n",
    "#Returns(s, a) <- empty list for all s, a\n",
    "\n",
    "\n",
    "#Repeat forever (for each episode)\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    #Generate an episode following pi: S0,A0,R1,S1,A1,R2,..ST-1,AT-1,RT\n",
    "    episode = []\n",
    "    s = env.reset() #s:(sum_hand(player), dealer open card, usable_ace 보유)\n",
    "    while True:\n",
    "        \n",
    "        \n",
    "    #G <- 0\n",
    "    \n",
    "    #Loop for each step of episode, t=T-1, T-2,...0\n",
    "    for s, a, r in episode[::-1]:\n",
    "        # G <- gamma*G + R_(t+1)\n",
    "        \n",
    "        #Unless the pair S_t, A_t appears in S_0,A_0 S_1,A_1..S_(t-1),A_(t-1):\n",
    "            #Append G to Returns(S_t, A_t)\n",
    "            #Q(S_t,A_t) <- average(Returns(S_t, A_t))\n",
    "       \n",
    "        \n",
    "        #A* <- argmax_a Q(S_t,a)\n",
    "        \n",
    "        #For all a:\n",
    "            #pi(a|S_t) <- 1-e + e/|A(S_t)| if a = A*\n",
    "            #          <- e/|A(St)|        if a != A*\n",
    "        \n",
    "                \n",
    "    if i % 5000 == 0:\n",
    "        print(f\"episode {i} completed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S6A6sg2EpH5j",
   "metadata": {
    "id": "S6A6sg2EpH5j"
   },
   "source": [
    "## Blackjack state value 시각화\n",
    "- np.meshgrid : 1차원 좌표 array 에서 N 차원 직사각형 격자 생성  \n",
    "- np.dstack : 2 차원 array를 3차원 array 로 stacking. (M, N) → (M, N, 1) 변환 후 3rd axis 를 depth-wise stack  \n",
    "- np.apply_along_axis : 주어진 축을 따라 1차원 슬라이스에 함수를 적용"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "022_MC_blackjack_control.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
