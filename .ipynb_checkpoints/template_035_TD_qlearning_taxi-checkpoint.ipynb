{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "above-appraisal",
   "metadata": {
    "id": "dbc339de"
   },
   "source": [
    "# 035_TD_qlearning_taxi\n",
    "## Q-Learning (off-policy TD control) for estimating $\\pi = \\pi^*$\n",
    "```\n",
    "6 discrete deterministic actions:\n",
    "    - 0: move south\n",
    "    - 1: move north\n",
    "    - 2: move east\n",
    "    - 3: move west\n",
    "    - 4: pickup passenger\n",
    "    - 5: drop off passenger\n",
    "    \n",
    "5 Passenger locations:\n",
    "    - 0: R\n",
    "    - 1: G\n",
    "    - 2: Y\n",
    "    - 3: B\n",
    "    - 4: in taxi\n",
    "\n",
    "4 Destinations:\n",
    "    - 0: R\n",
    "    - 1: G\n",
    "    - 2: Y\n",
    "    - 3: B\n",
    "    \n",
    "state space is represented by:\n",
    "        (taxi_row, taxi_col, passenger_location, destination)\n",
    "          5 * 5 * 5 * 4 = 500\n",
    "\n",
    "Rewards:\n",
    "    per-step : -1,\n",
    "    승객을 배달 : +20,\n",
    "    \"픽업\" 및 \"하차\" 행위를 불법으로 실행 : -10\n",
    "    \n",
    "파란색: 승객 - 4 개의 위치 중 승객이 기다리는 곳 표시\n",
    "마젠타색: 목적지\n",
    "노란색: 빈 택시 - 승객을 내려주고 난 빈 택시 표시\n",
    "녹색: - 승객이 탑승한 택시 표시\n",
    "```\n",
    "<img src=\"https://miro.medium.com/max/1260/1*toX5ZWcYxXtsaXE6hQJ1ag.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-fundamental",
   "metadata": {
    "id": "85bab53c"
   },
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/Xmyub/btqydBg48hF/4ZwGr1XshIOWO10P95WZKK/img.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []  # agent 가 episode 별로 얻은 score 기록\n",
    "steps = []  # agent 가 episode 별로 목표를 찾아간 step 수 변화 기록\n",
    "greedy = [] # epsilon delay history 기록\n",
    "\n",
    "#Initialize Q(s,a) for all s, a arbitrarily except Q(terminal,.)=0\n",
    "\n",
    "\n",
    "#Loop for each episode:\n",
    "for episode in range(num_episodes):\n",
    "    #Initialize S\n",
    "    \n",
    "    #Loop for each step of episode:\n",
    "    step = 0\n",
    "    score = 0\n",
    "    while True:\n",
    "        step += 1\n",
    "        # Choose A from S using policy derived from Q (eg. e-greedy)\n",
    "        # behavior policy : e-greedy\n",
    "        \n",
    "        \n",
    "        #Take action A, observe R, S'\n",
    "       \n",
    "        \n",
    "        #Q(S,A) <- Q(S,A) + alpha[R + gamma*max_aQ(S',a) - Q(S, A)]\n",
    "        #자신이 따르는 정책에 상관없이 최적 행동가치함수 q*를 직접 근사\n",
    "        # target policy : greedy policy\n",
    "        \n",
    "        #S <- S'\n",
    "        \n",
    "        # until S is terminal\n",
    "        \n",
    "        \n",
    "    steps.append(step)\n",
    "    scores.append(score)\n",
    "    greedy.append(epsilon)\n",
    "    \n",
    "    if episode % 100 == 0:\n",
    "        print(f\"last 100 평균 score is {np.mean(scores[-100:])}\" )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "035_TD_qlearning_taxi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
