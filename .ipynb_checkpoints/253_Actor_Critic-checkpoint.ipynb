{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "SXe72SuamiHi",
   "metadata": {
    "id": "SXe72SuamiHi"
   },
   "source": [
    "# 253. One-step Actor-Critic(episodic)\n",
    "\n",
    "- 두개의 parameter set 을 학습 \n",
    "\n",
    "$$\\theta_{t+1}=\\theta_t + \\alpha\\nabla\\log{\\pi_\\theta}(A_t|S_t)[R_{t+1}+\\gamma\\hat{v}(S_{t+1},w) - \\hat{v}(S_t, w)]$$\n",
    "\n",
    "- TD error (delta) \n",
    "$$R_{t+1}+\\gamma\\hat{v}(S_{t+1},w) - \\hat{v}(S_t, w)$$\n",
    "\n",
    "- Value network parameter update\n",
    "$$w \\leftarrow w + \\alpha^w\\delta\\nabla\\hat{v}(S, w)$$\n",
    "\n",
    "- Policy network parameter update\n",
    "$$\\theta \\leftarrow \\theta + \\alpha^\\theta \\delta\\nabla\\log{\\pi}(A|S, \\theta)$$\n",
    "\n",
    "- python 구현 :\n",
    "\n",
    "```python\n",
    "            td_target = r_batch + gamma * model.v(s_next_batch) * (1-done_batch)\n",
    "            delta = td_target - model.v(s_batch)\n",
    "        \n",
    "            pi = model.pi(s_batch)\n",
    "            pi_a = pi.gather(1, a_batch)\n",
    "            \n",
    "            loss = -1 * torch.log(pi_a) * delta + F.smooth_l1_loss(model.v(s_batch), td_target)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7Q7LxFUsmXUB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Q7LxFUsmXUB",
    "outputId": "1840d477-3bb6-4c11-df9f-8673acff54f4"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# install required system dependencies\n",
    "apt-get update \n",
    "apt-get install -y xvfb x11-utils\n",
    "# install required python dependencies (might need to install additional gym extras depending)\n",
    "pip install -q gym[box2d]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "xNPit6lIma23",
   "metadata": {
    "id": "xNPit6lIma23"
   },
   "outputs": [],
   "source": [
    "import pyvirtualdisplay\n",
    "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
    "                                    size=(1400, 900))\n",
    "_ = _display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081007c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "081007c7",
    "outputId": "b04f2e78-0aee-49b0-8fc1-83c1097d6826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import time\n",
    "import os\n",
    "from IPython import display\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa0ba42c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa0ba42c",
    "outputId": "b4af365f-8160-4005-a301-dcbc93aa81a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# env_name = 'Pendulum-v1'\n",
    "# env_name = 'CartPole-v1'\n",
    "env_name = 'LunarLander-v2'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "if env_name == 'Pendulum-v1':\n",
    "    n_actions = env.action_space.shape[0]  \n",
    "    action_space = np.arange(env.action_space.shape[0]) \n",
    "else:\n",
    "    n_actions = env.action_space.n\n",
    "    action_space = np.arange(env.action_space.n)\n",
    "    \n",
    "print(n_actions, action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304376c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "304376c7",
    "outputId": "d344043c-29f2-4e3c-bc27-2204b16eb208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0,  최근 100 episode 평균 reward -127.61\n",
      "episode 100,  최근 100 episode 평균 reward -301.87\n",
      "episode 200,  최근 100 episode 평균 reward -483.04\n",
      "episode 300,  최근 100 episode 평균 reward -297.17\n",
      "episode 400,  최근 100 episode 평균 reward -452.24\n",
      "episode 500,  최근 100 episode 평균 reward -250.37\n",
      "episode 600,  최근 100 episode 평균 reward -211.31\n",
      "episode 700,  최근 100 episode 평균 reward -162.69\n",
      "episode 800,  최근 100 episode 평균 reward -117.42\n",
      "episode 900,  최근 100 episode 평균 reward -158.61\n",
      "episode 1000,  최근 100 episode 평균 reward -148.07\n",
      "episode 1100,  최근 100 episode 평균 reward -140.35\n",
      "episode 1200,  최근 100 episode 평균 reward -116.00\n",
      "episode 1300,  최근 100 episode 평균 reward -99.08\n",
      "episode 1400,  최근 100 episode 평균 reward -92.36\n",
      "episode 1500,  최근 100 episode 평균 reward -91.84\n",
      "episode 1600,  최근 100 episode 평균 reward -116.52\n",
      "episode 1700,  최근 100 episode 평균 reward -67.66\n",
      "episode 1800,  최근 100 episode 평균 reward -72.69\n",
      "episode 1900,  최근 100 episode 평균 reward -81.29\n",
      "episode 2000,  최근 100 episode 평균 reward -71.68\n",
      "episode 2100,  최근 100 episode 평균 reward -71.93\n",
      "episode 2200,  최근 100 episode 평균 reward -70.06\n",
      "episode 2300,  최근 100 episode 평균 reward -88.11\n",
      "episode 2400,  최근 100 episode 평균 reward -78.18\n",
      "episode 2500,  최근 100 episode 평균 reward -65.75\n",
      "episode 2600,  최근 100 episode 평균 reward -81.05\n",
      "episode 2700,  최근 100 episode 평균 reward -82.97\n",
      "episode 2800,  최근 100 episode 평균 reward -85.20\n",
      "episode 2900,  최근 100 episode 평균 reward -81.81\n"
     ]
    }
   ],
   "source": [
    "# A differentiable policy parameterization pi(a|s,theta) - policy network\n",
    "# A differentiable state-value function parameterization v(s,w) - value network\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, input_dims, n_actions):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.fc1 = nn.Linear(*input_dims, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc_pi = nn.Linear(128, n_actions)\n",
    "        self.fc_v = nn.Linear(128, 1)\n",
    "\n",
    "    def pi(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc_pi(x)\n",
    "        prob = F.softmax(x, dim=-1)\n",
    "        return prob\n",
    "    \n",
    "    def v(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        v = self.fc_v(x)\n",
    "        return v\n",
    "\n",
    "# Select step-size parameters 0 < alpha < 1\n",
    "alpha = 0.001 #0.0002  # 0.001\n",
    "#Choose discount rate 0<gamma<1\n",
    "gamma = 0.98\n",
    "#Chose max number of episodes N\n",
    "N = 3000  \n",
    "\n",
    "batch_size = 32\n",
    "# Initialize the parameters theta and state-value weights w\n",
    "model = ActorCritic(env.observation_space.shape, n_actions).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=alpha)\n",
    "\n",
    "# rendering = True\n",
    "\n",
    "total_rewards = []\n",
    " \n",
    "# loop forever(for each episode):\n",
    "for episode in range(N):\n",
    "    # Initialize S (first state of episode)\n",
    "    s = env.reset()\n",
    "\n",
    "    done = False\n",
    "    \n",
    "    batch_rewards = []\n",
    "    batch_actions = []\n",
    "    batch_states = []\n",
    "    batch_next_state = []\n",
    "    batch_done = []\n",
    "    \n",
    "    # Loop while S is not terminal(for each time step):\n",
    "    while not done:\n",
    "        # A ~ pi(.|S,theta) - policy network에서 action 하나를 sampling\n",
    "        probs = model.pi(torch.from_numpy(s).float().to(device)).detach().cpu().numpy()\n",
    "        a = np.random.choice(action_space, p=probs)\n",
    "        # Take action A, observe S', R\n",
    "        s_, r, done, _ = env.step(a)\n",
    "        \n",
    "        batch_states.append(s)\n",
    "        batch_actions.append([a])\n",
    "        batch_rewards.append([r])\n",
    "        batch_next_state.append(s_)\n",
    "        done_mask = 0 if done else 1\n",
    "        batch_done.append([done_mask])\n",
    "        \n",
    "        # S <- S'\n",
    "        s = s_\n",
    "        \n",
    "#         if rendering and (episode > N * 0.98):\n",
    "#             env.render()\n",
    "            \n",
    "        if done:\n",
    "            s_batch = torch.FloatTensor(np.array(batch_states)).to(device)\n",
    "            a_batch = torch.LongTensor(np.array(batch_actions)).to(device)\n",
    "            r_batch = torch.FloatTensor(np.array(batch_rewards)).to(device)\n",
    "            s_next_batch = torch.FloatTensor(np.array(batch_next_state)).to(device)\n",
    "            done_batch = torch.FloatTensor(np.array(batch_done)).to(device)\n",
    "            \n",
    "            # delta <- R + gamma * v(S',w) - v(S,w) (if S' is terminal, then v(S',w) = 0)\n",
    "            td_target = r_batch + gamma * model.v(s_next_batch) * (1-done_batch)\n",
    "            # advantage = reward + gamma * v(S',w) - v(S,w) --> advantage = delta\n",
    "            delta = td_target - model.v(s_batch)\n",
    "            \n",
    "            # value network parameter update :\n",
    "            # w <- w + alpha * delta * gradient(v(S,w)) \n",
    "            # policy network parameter update :\n",
    "            # theta <- theta + alpha * I * delta * gradient(pi(A|S,theta)) \n",
    "            pi = model.pi(s_batch)\n",
    "            pi_a = pi.gather(1, a_batch)\n",
    "            \n",
    "            # loss = -1 * policy.logprob(action) * advantage + critic loss\n",
    "            loss = -1 * torch.log(pi_a) * delta \\\n",
    "                        + F.smooth_l1_loss(model.v(s_batch), td_target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_rewards.append(sum(r_batch.detach().cpu().numpy()))\n",
    "            \n",
    "    if episode % 100 == 0:\n",
    "        avg_score = np.mean(total_rewards[-100:])\n",
    "        print(f'episode {episode},  최근 100 episode 평균 reward {avg_score: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862a6259",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "862a6259",
    "outputId": "ef8402cb-6fec-4988-be21-1653e28f9105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished after -72.1 rewards\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hV9Z3v8fc393ANkHAxBBGIIoqig6korYKltU4dYVodOzpw5jCHmdP61M6htbadx9o5VR+nQs+xtVSoAjoW5EhLkbECcittVQgUJYBIQC6JyMXIJdyS7HzPH3sFN9fcs7P2/ryeZz9Z67fW2vv7i9tPFr/9W3uZuyMiIuGREu8CRESkcRTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMq0W3GZ2u5ltNbNSM3u4tV5HRCTZWGvM4zazVOB9YAxQBqwFvubum1v8xUREkkxrnXEXAaXuvsPdq4C5wF2t9FoiIkklrZWeNx/YE7NeBnzmQjubmS7fFBE5i7vb+dpbK7jrZWaTgEnxen0RkbBqreAuBwpi1vsGbae5+3RgOuiMW0SkMVprjHstUGhml5lZBnAvsLCVXktEJKm0yhm3u9eY2QPAYiAVeN7dN7XGa4mIJJtWmQ7Y6CI0VCIico4LfTipKydFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMs2656SZ7QSOAhGgxt2Hm1l34GWgP7ATuMfdP2lemSIiUqclzrhHufswdx8erD8MLHP3QmBZsC4iIi2kNYZK7gJmB8uzgbGt8BoiIkmrucHtwBIzW2dmk4K2Xu6+N1j+COjVzNcQEZEYzRrjBka6e7mZ9QSWmtl7sRvd3c3Mz3dgEPSTzrdNREQuzNzPm6uNfyKzR4FK4H8At7r7XjPrA6x09yvqObZlihARSSDubudrb/JQiZl1NLPOdcvAF4ASYCEwIdhtAvC7pr6GiIicq8ln3GY2APhtsJoG/NrdHzOzHsA8oB+wi+h0wIp6nktn3CIiZ7nQGXeLDZU0h4JbRORcLT5UIiIi8aHgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMjUG9xm9ryZ7Tezkpi27ma21My2BT+7Be1mZk+bWamZvWtm17dm8SIiyaghZ9yzgNvPansYWObuhcCyYB3gS0Bh8JgETGuZMkVEpE69we3ufwAqzmq+C5gdLM8Gxsa0v+BRbwE5ZtanpYoVEZGmj3H3cve9wfJHQK9gOR/YE7NfWdB2DjObZGbFZlbcxBpERJJSWnOfwN3dzLwJx00HpgM05XgRkWTV1DPufXVDIMHP/UF7OVAQs1/foE1ERFpIU4N7ITAhWJ4A/C6mfXwwu+RG4HDMkIqIiLQAc7/4KIWZzQFuBXKBfcAPgQXAPKAfsAu4x90rzMyAnxOdhXIc+Ed3r3cMW0MlIiLncnc7X3u9wd0WFNwiIue6UHDrykkRkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQUXCLiISMgltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iETL3BbWbPm9l+MyuJaXvUzMrNbEPwuCNm2/fMrNTMtprZF1urcBGRZNWQmwV/DqgEXnD3q4O2R4FKd3/qrH2HAHOAIuAS4A3gcneP1PMauuekiMhZmnzPSXf/A1DRwNe5C5jr7qfc/QOglGiIi4hIC2nOGPcDZvZuMJTSLWjLB/bE7FMWtJ3DzCaZWbGZFTejBhGRpNPU4J4GDASGAXuBKY19Anef7u7D3X14E2sQEUlKTQpud9/n7hF3rwVm8OlwSDlQELNr36BNRERaSJOC28z6xKyOA+pmnCwE7jWzTDO7DCgE1jSvRBERiZVW3w5mNge4Fcg1szLgh8CtZjYMcGAn8M8A7r7JzOYBm4Ea4Bv1zSgREZHGqXc6YJsUoemAIiLnaPJ0QBERaV8U3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIhU29wm1mBma0ws81mtsnMHgzau5vZUjPbFvzsFrSbmT1tZqVm9q6ZXd/anRARSSYNOeOuASa7+xDgRuAbZjYEeBhY5u6FwLJgHeBLRO/uXghMAqa1eNUiIkms3uB2973uvj5YPgpsAfKBu4DZwW6zgbHB8l3ACx71FpBjZn1avHIRkSTVqDFuM+sPXAe8DfRy973Bpo+AXsFyPrAn5rCyoO3s55pkZsVmVtzImkVEklqDg9vMOgHzgW+5+5HYbe7ugDfmhd19ursPd/fhjTlORCTZNSi4zSydaGi/5O6/CZr31Q2BBD/3B+3lQEHM4X2DNhERaQENmVViwHPAFnefGrNpITAhWJ4A/C6mfXwwu+RG4HDMkIqIiDSTRUc5LrKD2UhgNbARqA2av090nHse0A/YBdzj7hVB0P8cuB04Dvyju190HNvMGjXMIiKSDNzdztdeb3C3BQW3iMi5LhTcunJSRCRk2kVwd+/enfvuu4/u3bvHuxQRkXavXQyVDB8+3NeuXcv777/PiRMnAFi0aBGrV68+vU9xcTEVFRXxKlFEpM1daKgkra0LuRAz44orrji9PmzYsDO2r1+//nRwr1q1itdeew2A48eP895777VdoSIicdZuzriLixt+AWVszRUVFSxduvT0+vr163nllVcAqK6upqysrOUKFRFpQ+16Vkljg/tiamtrqampAeDw4cP8+te/Ph3027ZtY+7cuaf3O3ToUIu8pohIa0ia4L6Y6upqjh07BkSHWH7xi19QVVUFwCuvvMKuXbuora292FOIiLQZBXc99u3bx8yZM5k1axZbt26Nay0iIqB53PXq1asXDz/8MG+88QZr167l7rvvpmPHjvEuS0TkHDrjvgB3Z82aNWzZsoUpU6ZQUlIS75JEJMloqKSJ3J2jR4/y+uuvs2zZMn7zm99w8ODBeJclIklAwd0CIpEIJSUlrFy5klmzZrFp0yaqq6vjXZaIJCgFdwurrKzk5ZdfZsOGDcyaNYvKysp4lyQiCUbB3UoikQi7du1iypQpbNmyhRUrVsS7JBFJEAruNnDkyBFWrVrFL37xC0pKSnTVpog0i4K7jW3dupXZs2ezdOlSSkpKOHnyZLxLEpGQUXDHgbvj7ixZsoT/+I//oLS0lD179sS7LBEJCV2AEwdmRkpKCrfffjtLliyhuLiYxx9/nN69e+viHhFpsobcLLjAzFaY2WYz22RmDwbtj5pZuZltCB53xBzzPTMrNbOtZvbF1uxAWKSlpdGzZ0+++93vsnXrVhYtWsRXv/pVMjIy4l2aiIRMQ24W3Afo4+7rzawzsA4YC9wDVLr7U2ftPwSYAxQBlwBvAJe7e+RCr5GoQyX1OXHiBOvWrWPGjBm8+eabbNu2Ld4liUg70uShEnff6+7rg+WjwBYg/yKH3AXMdfdT7v4BUEo0xOUs2dnZjBw5ktmzZ7N8+XKeeuoprrrqqniXJSLtXKPGuM2sP3Ad8HbQ9ICZvWtmz5tZt6AtH4j9BK6Miwe9AH379mXy5MksXryYp59+msGDB8e7pDb3+OP/zJNPwtVXw5AhcMkl8a6o7d16663MmnUFd9wBV10FgwdDamq8q5L2psG3LjOzTsB84FvufsTMpgH/G/Dg5xTgvzfi+SYBkwD69evXmJoTWn5+Pg888AD33nsv8+bNY8qUKezcuZP2MPuntQ0dOoA+fWD06Oj63r2weXN0+fXXobQU3OGjjyBywYG3cMvLy6OoqJK6f3jV1MCf/wzV1VBWBgsWRNsPH4ajR+NXp8RXg4LbzNKJhvZL7v4bAHffF7N9BrAoWC0HCmIO7xu0ncHdpwPTITrG3ZTiE5WZkZeXx9e//nXuv/9+Zs2axdSpUykrK0uKGz1YMKp3ySWfnnWPGhUN7UgEFi+GEyeiwf6f/xm/OltT3e8gPR1uuSW67A733x9dLimBuq+Nf+EF2Lfv3OeQxNWQWSUGPAdscfepMe19YnYbB9R97+lC4F4zyzSzy4BCYE3LlZw8zIyuXbvyzW9+k3fffZcnn3wyaf91UlsbDe2aGjh+HI4di4Z3Mqn7wxWJwMmT0d/BsWPR340kl4accd8M/AOw0cw2BG3fB75mZsOIDpXsBP4ZwN03mdk8YDNQA3zjYjNKpH51AT558mQ+97nP8cQTT7Bw4cKEPPt2jz4gOjSwIXjHLV4MO3ZEt1VUJH5Y1f0eampg+XKoqoLycli4MLq9sjL5/nDJp+oNbnf/I3C+KSmvXeSYx4DHmlGXnIeZUVRUxJw5c1i/fj2PP/44S5cuPX3fzLCrrIT/+q/o8EdtbXQM98CBeFfV9jZsgBkzYNeu6O9h9+7E/0MlZxo1ahT7LjL+pSsnQygrK4ubbrqJBQsWsGzZMu64446EuBJz92549NHoh5A7diRnaANMnQorVkR/Bzt3KrSTSZcuXRg3bhxz5swhOzv7gvspuEMsLS2NkSNHsmjRIl599VW+/OUv07lz53iXlRBG9+nDjJEjubZ793iXIkmic+fOTJ8+nfnz59OrV6+L7qvgTgBmxqhRo1iwYAHz589n7NixdOrUKd5ltSozw+y8F5U1W1FeHj8bMYK/Lihg/KBB5x0nvJC8zEwG64+nNIKZ0bNnT2bMmME999zToPe1gjuBpKamMmbMGObOncvChQsT9rtQUswYfMklDOrdu1HHDOjShX+5+up6g/hUJMIf9+2j1p3jNTV0Sk/n3v79GZGXd9FjR/Towb8MGMA/XHopmSn6X0vqZ2bceeedlJSUcPfddzf4ZKTBF+BIeGRmZjJq1ChuvPFG1q1bx5QpUxJmFkqKGTddcQVdOnTgRFUVZR9XcKLq1Ont2dldyc0dAMAnn+yhsjJ6Y+fRffvy6y98gUhtLX/48EM2V1Rc8DXeqajgZ5s3s/XwYWZt28bDV13FiLw8jkciTHrzTT68wHSOz+bmkp+dTS1wc24uy/fvb7mOS8Lp0aMH48eP55FHHiEnJ6dRxyq4E1jdd6EMHz6cdevW8cQTT7BkyZLQ3uC4c+eedMjO4Rg55GR1o2PHbG4aOYqamMsoszJyyO0yiFqv5sOP32H16unU1tZw+NQpUs3I69iRfy8q4u+XLKHqIn/ISj75hJJPPiHdjGp3zIwjVVUXPea5Dz7gi717c6iqijUX+cMgkpuby4svvsgXv/jFJg35KbiTQFZWFjfffDMLFizgrbfe4oknnmDVqlUcO3Ys3qVdVEZGB66++q/JzIyO13frcimdO/T8dHtqJ67oeOaXcqWlZJKd3p1TNZUcOfER2dldOXbsY9bu38+80lLeOXiQBTt2XDSAY1W7M2PbNrYfPcqbBw5w8NSpC+77cVUVr5SVkZmSQmVNTRN6LInOzJgwYQL/+q//yjXXXNPk51FwJ5HYWSgrV65k6tSprFq1iqPt9EsvevYsZNClt9Cn03UAZKf3IDP1zA/+LnS2kpHakZ6dB5Offw3vvx+9gfP/XLmySXWUHz/Oizt2NGjfqtraBv9RkOSSkpLC+PHj+fnPf97s6bv6BCUJxc5CmTlzJr179261GRrNlZ6STbfsy+iWfRlZaV1Ozyapb1aJmdE161J65hWSlpbZhhWLnKugoIBp06bxzDPPtMg1FzrjTmKpqamMGzeOW265hWeffZYNGzbw6quvcuoiwwFh0jE9j5yu+aSnZ1FTkxh9knBJSUmhb9++zJs3j6KiohY7QdIZd5JLSUkhNzeXH/zgB7zwwgu88cYbTJw4kcLCwjhXZnTtegkd0vOa/AxpKVn06jyUyy67sQXrEmm4Bx98kOLi4hYNbdAZt8Som4UycuRIysvLmTNnDitXrmT58uWcaINvNEpPzyIzszOnTh0lJSWV3r2vpFv2gCY/n5nRIb0HXTr3ITU1g0gkMb7TRdo/M+Nb3/oWjz322EUvXW8qnXHLeeXn5/Ptb3+bhQsXsmrVKp577rlmfQpen7S0LLrlXMpnbrifzMyWu/IwJ6s/vXteSXZ219NtWVldOP/3pok03+WXX87rr7/eaqENOuOWeqSkpHDDDTdwww038Ld/+7esWLGC1157jVWrVvHBBx9Q00LT3oYO/Wt697iS6wf0pKa2irVrX2qR5zUz0lKzyMjoQEpKGoWFn6Mg/zpKd/yRXbvWJMWdhaRtZGRkMGzYMGbOnMmQIUNa9bV0xi0NlpOTw7hx43j22WcpKSlh5syZXHvttXRv5hcx5eYOoH/+CDLTunC86mOOHt2He8tMqTNS6dXxagYMGEGXLr258oovcE3BvQwd8mWysxt3tZrIhaSnp/PDH/6QP/3pT1x55ZWt/noKbmm0lJQUMjIyuO+++/jzn//MmjVreOSRR/jsZz9Lenp6o56re/dLubloElf2+htqak/y1uZfsWnT71vs8vzoB0LRqYMnTx7hyJF9GKkMzP08f3XdPWRkdGiR15HkNWzYMKZNm8ZDDz1EWlpam0ytVXBLk5kZHTp0YODAgfzoRz9i0aJFvPTSS0ycOJHc3Nx638ApKWn071/EJTnX4w6VJ/aza9daamtb54ZJJ08eYd1fXuaDT5bTKaMX/XoX0bPn5a3yWpIcrrnmGl555RUmTpxIWlrbjTwruKXFdOnShbvvvpsZM2bw9ttvs3jxYm677bbzBnhqajpDh97JDVf8N3Ky+rHlowV8dHAzhw9/2OJ1ZaR2IjurG+np2Rw5so+dZW/z8fFSLus2ir+69u/o0qVP/U8iEiMrK4uvfOUr/Pa3v2XgwIFt/voNuVlwlpmtMbN3zGyTmf0oaL/MzN42s1Ize9nMMoL2zGC9NNjev3W7IO2NmTFgwADGjBnDokWLWL16NT/+8Y8ZNGjQ6X26d+vHkIFfomfHq/j4RCnb9/yBo0c//TY9d+fEicNURZp/OX6XzHx69ricTp3ycI9QWrqaDw78gapIJf263cSVg8eQnt46n/5L4unQoQNTp05l3rx5DBjQ9OmqzdGQc/tTwGh3rzSzdOCPZvZ74H8BP3X3uWb2S2AiMC34+Ym7DzKze4Engb9rpfqlnav7gqubbrqJ8ePHs27dOmbMmEFG+uWkp2Zz4Ph7rH//P9myZSnw2dPHuUfYvbuYy/rcRE7WpRd8/lqPUBU5SuzkkAPHN58R+O5QtncDlZXRe6EdOfIR721bQm6XQQzofhuF/Uaz96MSdu9e3+L9l8QyatQo/u3f/o1Ro0bF9WsiGnKzYAcqg9X04OHAaODvg/bZwKNEg/uuYBngFeDnZmaueVdJzcwoKCigoKCAO++8kxMnqli+/F2ef34uOz5YdsFL0ms9QnXkeLBcw75jG6n1T8fAayKn2Hek5Ixjdu9ez4kTh2JanL17t1Bd/elFRLt2FdOl83yyr+pObofLKSi4nt27/0L0rS1ypuzsbEaMGMFLL71E70bcwKO1NGg03cxSgXXAIOAZYDtwyN3rJvGWAfnBcj6wB8Dda8zsMNADONiCdUuIpaam0qlTNnfeWcSYMdeycePXeO211ygrK6Njx46n51ZHIpUcq97N+4fnB+vV7Ny1htraT+eOV1efZM+eMwM3Eqk5ZzpherqRnn7mDJKDH29h3/G1eGUt27cvo0OH+A+X7Ny5k8OHD5Oamkok0jof0krjdOzYkV/96leMHTuWrKyseJcDNDC43T0CDDOzHOC3wODmvrCZTQImAfTr16+5TychZGZkZ2dRVFREUVERFRUVfP/73z9jn4yMDphFP4pxd6qqWvY7xDMyOuDuVFc/0KLP21wvvvgipaWlrF27lnfeeQcgIe5gFDZ1N/C95557SGlHt6Nr1PwVdz9kZiuAEUCOmaUFZ919gfJgt3KgACgzszSgK/DxeZ5rOjAdYPjw4fr3qTTwQp7WuhFv1/p3aUPf+c53ANi/fz8Vwd10fvazn1FeXs66desoKyuLZ3lJ4a677uInP/kJAwcObFehDQ0IbjPLA6qD0M4GxhD9wHEF8FVgLjAB+F1wyMJg/c1g+3KNb4s0Tc+ePenZM3rXn2eeeQaAbdu2ceDAAVavXs2rr77KoUOH2LRpUzzLTAj9+vXj0ksv5dvf/ja5ubkMHjy42VcFtxarL1PN7BqiHz6mEp0+OM/d/93MBhAN7e7AX4D73f2UmWUBLwLXARXAve5+0duHDB8+3IuLi5vdGZFkdODAAd58800OHTrET37yEyKRCIcPH+bDD1t+Tnwi6dy5M3379mXChAlceeWVDB48mMsvbz8XZA0fPpzi4uLzTl2pN7jbgoJbpPnc/fQ4+I4dO1i5ciV79+7ll7/8JbW1tezfvz+pv1SrW7duZGZmctttt3HLLbfQv39/Ro8eTUpKSru8A9TFglvfDiiSIMyM1NRUAAoLCyksLCQSiTB58mROnTrFjBkzOHnyJLNnz2b//v2cPHkyoWeupKenk5GRQWFhIWPHjmXcuHEMHDjwdHuY6YxbJIm4OxUVFVRXVzN//nw2btxIJBJh3rx5HDt2LPRBnpqaSk5ODl/5ylcYPXo0t9xyC1lZWeTkhO+bIDVUIiIXVFtbe/q71WfMmMH27duB6IegYfjQMzU1lTFjxnD99dczfvx4MjIy6N+/f7sc/mgMDZWIyAWlpKSc/qKkp5566nR7eXk5u3btOmPf48eP8+STT3Ly5Mkz2rdv387evXtbv1ii00aHDBlCXl4ekydPJi0tjeuuuy70wx+NoeAWkfPKz88nPz//nPbPf/7z57Rt3LiRnTt3ntF28OBBpk6des7wS1lZGUePNvzLwzIyMhg4cCAZGRk89NBDDBo0iKKiogYfn4gU3CLSbEOHDmXo0KFntLk748ePP2ffFStWnBPyZWVlTJ8+/Zx9/+mf/omhQ4cybtw4zKzdzgBpawpuEWkVsbNcYp3vjD0SifDQQw+d056ZmXne50h2Cm4RibvU1FQ6dNBt5BqqfV2ALyIi9VJwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhEy9wW1mWWa2xszeMbNNZvajoH2WmX1gZhuCx7Cg3czsaTMrNbN3zez61u6EiEgyach3lZwCRrt7pZmlA380s98H277j7q+ctf+XgMLg8RlgWvBTRERaQL1n3B5VGaymB4+L3TbnLuCF4Li3gBwz69P8UkVEBBo4xm1mqWa2AdgPLHX3t4NNjwXDIT81s8ygLR/YE3N4WdAmIiItoEHB7e4Rdx8G9AWKzOxq4HvAYOAGoDvw3ca8sJlNMrNiMys+cOBAI8sWEUlejZpV4u6HgBXA7e6+NxgOOQXMBOruJVQOFMQc1jdoO/u5prv7cHcfnpeX17TqRUSSUENmleSZWU6wnA2MAd6rG7e26H2ExgIlwSELgfHB7JIbgcPu3jZ3ERURSQINmVXSB5htZqlEg36euy8ys+VmlgcYsAH4l2D/14A7gFLgOPCPLV+2iEjyqje43f1d4LrztI++wP4OfKP5pYmIyPnoykkRkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQUXCLiISMgltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyJi7x7sGzOwosDXedbSSXOBgvItoBYnaL0jcvqlf4XKpu+edb0NaW1dyAVvdfXi8i2gNZlaciH1L1H5B4vZN/UocGioREQkZBbeISMi0l+CeHu8CWlGi9i1R+wWJ2zf1K0G0iw8nRUSk4drLGbeIiDRQ3IPbzG43s61mVmpmD8e7nsYys+fNbL+ZlcS0dTezpWa2LfjZLWg3M3s66Ou7ZnZ9/Cq/ODMrMLMVZrbZzDaZ2YNBe6j7ZmZZZrbGzN4J+vWjoP0yM3s7qP9lM8sI2jOD9dJge/941l8fM0s1s7+Y2aJgPVH6tdPMNprZBjMrDtpC/V5sjrgGt5mlAs8AXwKGAF8zsyHxrKkJZgG3n9X2MLDM3QuBZcE6RPtZGDwmAdPaqMamqAEmu/sQ4EbgG8F/m7D37RQw2t2vBYYBt5vZjcCTwE/dfRDwCTAx2H8i8EnQ/tNgv/bsQWBLzHqi9AtglLsPi5n6F/b3YtO5e9wewAhgccz694DvxbOmJvajP1ASs74V6BMs9yE6Tx3gWeBr59uvvT+A3wFjEqlvQAdgPfAZohdwpAXtp9+XwGJgRLCcFuxn8a79Av3pSzTARgOLAEuEfgU17gRyz2pLmPdiYx/xHirJB/bErJcFbWHXy933BssfAb2C5VD2N/hn9HXA2yRA34LhhA3AfmApsB045O41wS6xtZ/uV7D9MNCjbStusP8DPATUBus9SIx+ATiwxMzWmdmkoC3078Wmai9XTiYsd3czC+3UHTPrBMwHvuXuR8zs9Law9s3dI8AwM8sBfgsMjnNJzWZmXwb2u/s6M7s13vW0gpHuXm5mPYGlZvZe7MawvhebKt5n3OVAQcx636At7PaZWR+A4Of+oD1U/TWzdKKh/ZK7/yZoToi+Abj7IWAF0SGEHDOrO5GJrf10v4LtXYGP27jUhrgZ+Bsz2wnMJTpc8n8Jf78AcPfy4Od+on9si0ig92JjxTu41wKFwSffGcC9wMI419QSFgITguUJRMeH69rHB5963wgcjvmnXrti0VPr54At7j41ZlOo+2ZmecGZNmaWTXTcfgvRAP9qsNvZ/arr71eB5R4MnLYn7v49d+/r7v2J/n+03N3vI+T9AjCzjmbWuW4Z+AJQQsjfi80S70F24A7gfaLjjD+Idz1NqH8OsBeoJjqWNpHoWOEyYBvwBtA92Bn1+M8AAACLSURBVNeIzqLZDmwEhse7/ov0ayTRccV3gQ3B446w9w24BvhL0K8S4JGgfQCwBigF/h+QGbRnBeulwfYB8e5DA/p4K7AoUfoV9OGd4LGpLifC/l5szkNXToqIhEy8h0pERKSRFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhMz/B/GMLiGQbtwJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "plt.figure(figsize=(6, 4))\n",
    "screen = env.render(mode='rgb_array')\n",
    "img = plt.imshow(screen)                   # only call this once\n",
    "    \n",
    "for i in range(1):\n",
    "    reward = 0\n",
    "    s = env.reset()\n",
    "    while True:\n",
    "        img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        probs = model.pi(torch.from_numpy(s).float().to(device)).detach().cpu().numpy()\n",
    "        a = np.random.choice(action_space, p=probs)\n",
    "\n",
    "        s_, r, done, _ = env.step(a)\n",
    "        \n",
    "        reward += r\n",
    "\n",
    "        s = s_\n",
    "\n",
    "        if done or reward >= 200:\n",
    "            print(f\"finished after {reward:.1f} rewards\")\n",
    "            break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd290e1b",
   "metadata": {
    "id": "dd290e1b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "053_Actor_Critic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
